{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1436057,"sourceType":"datasetVersion","datasetId":841381}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !git clone https://github.com/alexandrosstergiou/progressive-action-prediction","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T11:24:15.124876Z","iopub.execute_input":"2024-05-18T11:24:15.125331Z","iopub.status.idle":"2024-05-18T11:24:16.194935Z","shell.execute_reply.started":"2024-05-18T11:24:15.125306Z","shell.execute_reply":"2024-05-18T11:24:16.193772Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"fatal: destination path 'progressive-action-prediction' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -a /kaggle/input/ucf101/UCF101/UCF-101 /kaggle/working/progressive-action-prediction/data","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:32:43.318227Z","iopub.execute_input":"2024-05-18T10:32:43.319079Z","iopub.status.idle":"2024-05-18T10:34:52.792481Z","shell.execute_reply.started":"2024-05-18T10:32:43.319022Z","shell.execute_reply":"2024-05-18T10:34:52.790141Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\n# Count number of images\ndef count_videos_in_folder(folder_path):\n    video_count = 0\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            if file.endswith('.avi'):\n                video_count += 1\n    return video_count\n\nnum_of_videos = count_videos_in_folder(\"/kaggle/working/progressive-action-prediction/data/UCF-101\")\nprint(f'Total number of videos: {num_of_videos}')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:35:59.431953Z","iopub.execute_input":"2024-05-18T10:35:59.434355Z","iopub.status.idle":"2024-05-18T10:35:59.481830Z","shell.execute_reply.started":"2024-05-18T10:35:59.434269Z","shell.execute_reply":"2024-05-18T10:35:59.480486Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total number of videos: 13320\n","output_type":"stream"}]},{"cell_type":"code","source":"cd /kaggle/working/progressive-action-prediction","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:37:52.986290Z","iopub.execute_input":"2024-05-18T10:37:52.988589Z","iopub.status.idle":"2024-05-18T10:37:53.003170Z","shell.execute_reply.started":"2024-05-18T10:37:52.988501Z","shell.execute_reply":"2024-05-18T10:37:53.002099Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/alexandrosstergiou/adaPool.git","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:37:54.873068Z","iopub.execute_input":"2024-05-18T10:37:54.874072Z","iopub.status.idle":"2024-05-18T10:37:58.121255Z","shell.execute_reply.started":"2024-05-18T10:37:54.874014Z","shell.execute_reply":"2024-05-18T10:37:58.119505Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Cloning into 'adaPool'...\nremote: Enumerating objects: 232, done.\u001b[K\nremote: Counting objects: 100% (22/22), done.\u001b[K\nremote: Compressing objects: 100% (20/20), done.\u001b[K\nremote: Total 232 (delta 10), reused 4 (delta 2), pack-reused 210\u001b[K\nReceiving objects: 100% (232/232), 38.32 MiB | 34.95 MiB/s, done.\nResolving deltas: 100% (53/53), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"# cp -a /kaggle/input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist /kaggle/working/progressive-action-prediction/labels","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:58:04.447988Z","iopub.execute_input":"2024-05-18T10:58:04.448637Z","iopub.status.idle":"2024-05-18T10:58:04.457105Z","shell.execute_reply.started":"2024-05-18T10:58:04.448585Z","shell.execute_reply":"2024-05-18T10:58:04.454675Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# mv /kaggle/working/progressive-action-prediction/labels/ucfTrainTestlist /kaggle/working/progressive-action-prediction/labels/UCF-101","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:58:27.074562Z","iopub.execute_input":"2024-05-18T10:58:27.075121Z","iopub.status.idle":"2024-05-18T10:58:27.082372Z","shell.execute_reply.started":"2024-05-18T10:58:27.075079Z","shell.execute_reply":"2024-05-18T10:58:27.080637Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/progressive-action-prediction/labels","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:58:41.688880Z","iopub.execute_input":"2024-05-18T10:58:41.689451Z","iopub.status.idle":"2024-05-18T10:58:41.701407Z","shell.execute_reply.started":"2024-05-18T10:58:41.689408Z","shell.execute_reply":"2024-05-18T10:58:41.699552Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction/labels\n","output_type":"stream"}]},{"cell_type":"code","source":"!python label_format_conversion.py ","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:58:45.357263Z","iopub.execute_input":"2024-05-18T10:58:45.357802Z","iopub.status.idle":"2024-05-18T10:58:46.915729Z","shell.execute_reply.started":"2024-05-18T10:58:45.357765Z","shell.execute_reply":"2024-05-18T10:58:46.913755Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"!mv /kaggle/working/progressive-action-prediction/labels/UCF-101/trainlist01.txt /kaggle/working/progressive-action-prediction/labels/UCF-101/train_unsplit.csv\n!mv /kaggle/working/progressive-action-prediction/labels/UCF-101/testlist01.txt /kaggle/working/progressive-action-prediction/labels/UCF-101/test.csv","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:59:06.260551Z","iopub.execute_input":"2024-05-18T10:59:06.261076Z","iopub.status.idle":"2024-05-18T10:59:08.463723Z","shell.execute_reply.started":"2024-05-18T10:59:06.261037Z","shell.execute_reply":"2024-05-18T10:59:08.461723Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/progressive-action-prediction/labels/UCF-101","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:59:22.517869Z","iopub.execute_input":"2024-05-18T10:59:22.518385Z","iopub.status.idle":"2024-05-18T10:59:22.527055Z","shell.execute_reply.started":"2024-05-18T10:59:22.518346Z","shell.execute_reply":"2024-05-18T10:59:22.525682Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction/labels/UCF-101\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntestdf = pd.read_csv(\"test.csv\")\nprint(len(testdf))\ntestdf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:59:23.960242Z","iopub.execute_input":"2024-05-18T10:59:23.960778Z","iopub.status.idle":"2024-05-18T10:59:23.990196Z","shell.execute_reply.started":"2024-05-18T10:59:23.960738Z","shell.execute_reply":"2024-05-18T10:59:23.988914Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"3782\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"     ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n3777                     YoYo/v_YoYo_g06_c04.avi\n3778                     YoYo/v_YoYo_g07_c01.avi\n3779                     YoYo/v_YoYo_g07_c02.avi\n3780                     YoYo/v_YoYo_g07_c03.avi\n3781                     YoYo/v_YoYo_g07_c04.avi","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3777</th>\n      <td>YoYo/v_YoYo_g06_c04.avi</td>\n    </tr>\n    <tr>\n      <th>3778</th>\n      <td>YoYo/v_YoYo_g07_c01.avi</td>\n    </tr>\n    <tr>\n      <th>3779</th>\n      <td>YoYo/v_YoYo_g07_c02.avi</td>\n    </tr>\n    <tr>\n      <th>3780</th>\n      <td>YoYo/v_YoYo_g07_c03.avi</td>\n    </tr>\n    <tr>\n      <th>3781</th>\n      <td>YoYo/v_YoYo_g07_c04.avi</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the training data\ntrain_df = pd.read_csv('/kaggle/working/progressive-action-prediction/labels/UCF-101/train_unsplit.csv')\n\n# Split the data: 80% train, 20% validation\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Save the splits\ntrain_data.to_csv('/kaggle/working/progressive-action-prediction/labels/UCF-101/train.csv', index=False)\nval_data.to_csv('/kaggle/working/progressive-action-prediction/labels/UCF-101/val.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T10:59:46.656433Z","iopub.execute_input":"2024-05-18T10:59:46.657010Z","iopub.status.idle":"2024-05-18T10:59:48.419654Z","shell.execute_reply.started":"2024-05-18T10:59:46.656968Z","shell.execute_reply":"2024-05-18T10:59:48.418296Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"traindf = pd.read_csv(\"train.csv\")\nprint(len(traindf))\ntraindf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:02:32.932001Z","iopub.execute_input":"2024-05-18T11:02:32.932562Z","iopub.status.idle":"2024-05-18T11:02:32.964584Z","shell.execute_reply.started":"2024-05-18T11:02:32.932509Z","shell.execute_reply":"2024-05-18T11:02:32.963302Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"7628\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"      ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\n7623       PlayingDhol/v_PlayingDhol_g08_c02.avi 61\n7624     MoppingFloor/v_MoppingFloor_g12_c03.avi 55\n7625     ParallelBars/v_ParallelBars_g17_c04.avi 57\n7626  BasketballDunk/v_BasketballDunk_g23_c03.avi 9\n7627           SalsaSpin/v_SalsaSpin_g11_c06.avi 77","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7623</th>\n      <td>PlayingDhol/v_PlayingDhol_g08_c02.avi 61</td>\n    </tr>\n    <tr>\n      <th>7624</th>\n      <td>MoppingFloor/v_MoppingFloor_g12_c03.avi 55</td>\n    </tr>\n    <tr>\n      <th>7625</th>\n      <td>ParallelBars/v_ParallelBars_g17_c04.avi 57</td>\n    </tr>\n    <tr>\n      <th>7626</th>\n      <td>BasketballDunk/v_BasketballDunk_g23_c03.avi 9</td>\n    </tr>\n    <tr>\n      <th>7627</th>\n      <td>SalsaSpin/v_SalsaSpin_g11_c06.avi 77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"valdf = pd.read_csv(\"val.csv\")\nprint(len(valdf))\nvaldf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:02:49.887740Z","iopub.execute_input":"2024-05-18T11:02:49.888254Z","iopub.status.idle":"2024-05-18T11:02:49.907856Z","shell.execute_reply.started":"2024-05-18T11:02:49.888213Z","shell.execute_reply":"2024-05-18T11:02:49.906612Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"1908\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"          ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\n1903  HandstandWalking/v_HandstandWalking_g18_c03.av...\n1904  BoxingPunchingBag/v_BoxingPunchingBag_g18_c03....\n1905         MoppingFloor/v_MoppingFloor_g14_c03.avi 55\n1906      BasketballDunk/v_BasketballDunk_g17_c05.avi 9\n1907               GolfSwing/v_GolfSwing_g23_c06.avi 33","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1903</th>\n      <td>HandstandWalking/v_HandstandWalking_g18_c03.av...</td>\n    </tr>\n    <tr>\n      <th>1904</th>\n      <td>BoxingPunchingBag/v_BoxingPunchingBag_g18_c03....</td>\n    </tr>\n    <tr>\n      <th>1905</th>\n      <td>MoppingFloor/v_MoppingFloor_g14_c03.avi 55</td>\n    </tr>\n    <tr>\n      <th>1906</th>\n      <td>BasketballDunk/v_BasketballDunk_g17_c05.avi 9</td>\n    </tr>\n    <tr>\n      <th>1907</th>\n      <td>GolfSwing/v_GolfSwing_g23_c06.avi 33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"cd /kaggle/working/progressive-action-prediction","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:03:43.298231Z","iopub.execute_input":"2024-05-18T11:03:43.298765Z","iopub.status.idle":"2024-05-18T11:03:43.308732Z","shell.execute_reply.started":"2024-05-18T11:03:43.298725Z","shell.execute_reply":"2024-05-18T11:03:43.307759Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction\n","output_type":"stream"}]},{"cell_type":"code","source":"mkdir weights","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:03:56.480465Z","iopub.execute_input":"2024-05-18T11:03:56.481050Z","iopub.status.idle":"2024-05-18T11:03:57.596931Z","shell.execute_reply.started":"2024-05-18T11:03:56.480997Z","shell.execute_reply":"2024-05-18T11:03:57.595299Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"cd weights","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:04:12.265224Z","iopub.execute_input":"2024-05-18T11:04:12.265872Z","iopub.status.idle":"2024-05-18T11:04:12.277421Z","shell.execute_reply.started":"2024-05-18T11:04:12.265822Z","shell.execute_reply":"2024-05-18T11:04:12.275914Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction/weights\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:05:31.296948Z","iopub.execute_input":"2024-05-18T11:05:31.297854Z","iopub.status.idle":"2024-05-18T11:05:49.731486Z","shell.execute_reply.started":"2024-05-18T11:05:31.297807Z","shell.execute_reply":"2024-05-18T11:05:49.729787Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\n\n# https://drive.google.com/file/d/12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J/view?usp=sharing\"\nfile_id = '12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J'\nurl = f'https://drive.google.com/uc?id={file_id}'\noutput = \"/kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth\"\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:05:54.234131Z","iopub.execute_input":"2024-05-18T11:05:54.234660Z","iopub.status.idle":"2024-05-18T11:05:57.636380Z","shell.execute_reply.started":"2024-05-18T11:05:54.234614Z","shell.execute_reply":"2024-05-18T11:05:57.635020Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J\nFrom (redirected): https://drive.google.com/uc?id=12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J&confirm=t&uuid=3ea95ea3-55dd-492c-8f8b-645c8d252e9a\nTo: /kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth\n100%|██████████| 156M/156M [00:02<00:00, 71.5MB/s] \n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth'"},"metadata":{}}]},{"cell_type":"code","source":"# https://drive.google.com/file/d/12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J/view?usp=sharing\"\nfile_id = '12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J'\nurl = f'https://drive.google.com/uc?id={file_id}'\noutput = \"/kaggle/working/progressive-action-prediction/Tempr_h_movinet_ada_obs_03.pth\"\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:07:51.291147Z","iopub.execute_input":"2024-05-18T11:07:51.292363Z","iopub.status.idle":"2024-05-18T11:07:52.920996Z","shell.execute_reply.started":"2024-05-18T11:07:51.292302Z","shell.execute_reply":"2024-05-18T11:07:52.919650Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J\nFrom (redirected): https://drive.google.com/uc?id=12IEDxnZ8WS1f0eoN_CnEMYq1Lig4uZ8J&confirm=t&uuid=e2f084dc-4971-49a1-bb5a-a8d356f36ec8\nTo: /kaggle/working/progressive-action-prediction/Tempr_h_movinet_ada_obs_03.pth\n100%|██████████| 156M/156M [00:00<00:00, 170MB/s] \n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/progressive-action-prediction/Tempr_h_movinet_ada_obs_03.pth'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install \"coloredlogs==14.0\" \"dataset2database==1.1\" \"einops==0.4.0\" \"ffmpeg-python==0.2.0\" \"imgaug==0.4.0\" \"opencv-python>=4.2.0.32\" \"ptflops==0.6.8\" \"torch\" \"torchinfo\" \"torchvision\" \"youtube-dl==2020.3.24\" \"timm\" \"fvcore\" \"pytorchvideo\"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:31:19.082125Z","iopub.execute_input":"2024-05-18T11:31:19.082560Z","iopub.status.idle":"2024-05-18T11:31:48.980703Z","shell.execute_reply.started":"2024-05-18T11:31:19.082527Z","shell.execute_reply":"2024-05-18T11:31:48.979665Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting coloredlogs==14.0\n  Downloading coloredlogs-14.0-py2.py3-none-any.whl.metadata (12 kB)\nCollecting dataset2database==1.1\n  Downloading dataset2database-1.1-py3-none-any.whl.metadata (5.4 kB)\nCollecting einops==0.4.0\n  Downloading einops-0.4.0-py3-none-any.whl.metadata (10 kB)\nCollecting ffmpeg-python==0.2.0\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: imgaug==0.4.0 in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: opencv-python>=4.2.0.32 in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\nCollecting ptflops==0.6.8\n  Downloading ptflops-0.6.8.tar.gz (12 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nCollecting youtube-dl==2020.3.24\n  Downloading youtube_dl-2020.3.24-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nCollecting fvcore\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pytorchvideo\n  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting humanfriendly>=7.1 (from coloredlogs==14.0)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from ffmpeg-python==0.2.0) (1.0.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (1.16.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (9.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (3.7.5)\nRequirement already satisfied: scikit-image>=0.14.2 in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (0.22.0)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (2.33.1)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from imgaug==0.4.0) (1.8.5.post1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nCollecting yacs>=0.1.6 (from fvcore)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.1)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\nCollecting iopath>=0.1.7 (from fvcore)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting av (from pytorchvideo)\n  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nCollecting parameterized (from pytorchvideo)\n  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\nCollecting portalocker (from iopath>=0.1.7->fvcore)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2023.12.9)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (21.3)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug==0.4.0) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug==0.4.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug==0.4.0) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug==0.4.0) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug==0.4.0) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->imgaug==0.4.0) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading coloredlogs-14.0-py2.py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dataset2database-1.1-py3-none-any.whl (18 kB)\nDownloading einops-0.4.0-py3-none-any.whl (28 kB)\nDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nDownloading youtube_dl-2020.3.24-py2.py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: ptflops, fvcore, pytorchvideo, iopath\n  Building wheel for ptflops (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ptflops: filename=ptflops-0.6.8-py3-none-any.whl size=11852 sha256=d2c4b8a41071eb185f85b6817273dc82aa78bf9b1a813e0b67e4cccd874bf034\n  Stored in directory: /root/.cache/pip/wheels/65/78/dd/ee26db7b47fe0095e58d1020e16c93dc3ee6553e8547cc736c\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=1f3dd56fe669cc52c1665ed14b54f3ba475d3f19a15ab8c328be55c267a86d6c\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for pytorchvideo (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188685 sha256=5ca661b74340f77176c35d600660e7539955bc82a85841055519fdf74c6660a1\n  Stored in directory: /root/.cache/pip/wheels/ff/4e/81/0f72a543be9ed7eb737c95bfc5da4025e73226b44368074ece\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=a829080133844ca302597179d4f9a0b097345708dc978c720767ec1e5f40f42d\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built ptflops fvcore pytorchvideo iopath\nInstalling collected packages: youtube-dl, einops, dataset2database, yacs, portalocker, parameterized, humanfriendly, ffmpeg-python, av, iopath, coloredlogs, ptflops, fvcore, pytorchvideo\nSuccessfully installed av-12.0.0 coloredlogs-14.0 dataset2database-1.1 einops-0.4.0 ffmpeg-python-0.2.0 fvcore-0.1.5.post20221221 humanfriendly-10.0 iopath-0.1.10 parameterized-0.9.0 portalocker-2.8.2 ptflops-0.6.8 pytorchvideo-0.1.5 yacs-0.1.8 youtube-dl-2020.3.24\n","output_type":"stream"}]},{"cell_type":"code","source":"cd /kaggle/working/progressive-action-prediction/adaPool/pytorch","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:32:15.951645Z","iopub.execute_input":"2024-05-18T11:32:15.952059Z","iopub.status.idle":"2024-05-18T11:32:15.959991Z","shell.execute_reply.started":"2024-05-18T11:32:15.952024Z","shell.execute_reply":"2024-05-18T11:32:15.958843Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction/adaPool/pytorch\n","output_type":"stream"}]},{"cell_type":"code","source":"!make install","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:32:55.181102Z","iopub.execute_input":"2024-05-18T11:32:55.181948Z","iopub.status.idle":"2024-05-18T11:34:10.233021Z","shell.execute_reply.started":"2024-05-18T11:32:55.181915Z","shell.execute_reply":"2024-05-18T11:34:10.231906Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"rm -rf *.egg-info\nrm -rf build dist\npython setup.py install\n/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` and ``easy_install``.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://github.com/pypa/setuptools/issues/917 for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no g++ version bounds defined for CUDA version 12.1\n  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run training","metadata":{}},{"cell_type":"code","source":"cd /kaggle/working/progressive-action-prediction","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:34:34.407926Z","iopub.execute_input":"2024-05-18T11:34:34.408377Z","iopub.status.idle":"2024-05-18T11:34:34.416649Z","shell.execute_reply.started":"2024-05-18T11:34:34.408341Z","shell.execute_reply":"2024-05-18T11:34:34.415618Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/progressive-action-prediction\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:34:35.241649Z","iopub.execute_input":"2024-05-18T11:34:35.242031Z","iopub.status.idle":"2024-05-18T11:34:36.266444Z","shell.execute_reply.started":"2024-05-18T11:34:35.242000Z","shell.execute_reply":"2024-05-18T11:34:36.265423Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"LICENSE                         \u001b[0m\u001b[01;34madaPool\u001b[0m/  dataset.py    \u001b[01;34mlabels\u001b[0m/   train.py\nREADME.md                       \u001b[01;34mconfig\u001b[0m/   \u001b[01;34mfigures\u001b[0m/      \u001b[01;34mnetwork\u001b[0m/  \u001b[01;34mweights\u001b[0m/\nTempr_h_movinet_ada_obs_03.pth  \u001b[01;34mdata\u001b[0m/     inference.py  \u001b[01;34mrun\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train.py --video_per 0.3 --num_samplers 3 --gpus 0 --precision mixed --dataset UCF-101 --frame_size 224 --batch_size 64 --data_dir /kaggle/working/progressive-action-prediction/data/UCF-101/ --label_dir /kaggle/working/progressive-action-prediction/labels/UCF-101 --workers 10 --backbone movinet --end_epoch 2 --pretrained_dir /kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:41:37.837337Z","iopub.execute_input":"2024-05-18T11:41:37.837845Z","iopub.status.idle":"2024-05-18T11:41:45.030412Z","shell.execute_reply.started":"2024-05-18T11:41:37.837809Z","shell.execute_reply":"2024-05-18T11:41:45.029211Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n  warnings.warn(\n\u001b[32m2024-05-18 11:41:43\u001b[0m \u001b[35m1c41b535c9e1\u001b[0m \u001b[34mroot[174]\u001b[0m \u001b[1;30mINFO\u001b[0m CUDA_VISIBLE_DEVICES set to 0\n\u001b[32m2024-05-18 11:41:43\u001b[0m \u001b[35m1c41b535c9e1\u001b[0m \u001b[34mroot[174]\u001b[0m \u001b[1;30mINFO\u001b[0m Using pytorch version 2.1.2 (['/opt/conda/lib/python3.10/site-packages/torch'])\n\u001b[32m2024-05-18 11:41:43\u001b[0m \u001b[35m1c41b535c9e1\u001b[0m \u001b[34mroot[174]\u001b[0m \u001b[1;30mINFO\u001b[0m Start training with args:\n{\n    \"accum_grads\": 1,\n    \"attn_dropout\": 0.0,\n    \"backbone\": \"movinet\",\n    \"batch_size\": 64,\n    \"config\": null,\n    \"cross_dim_head\": 64,\n    \"cross_heads\": 1,\n    \"data_dir\": \"/kaggle/working/progressive-action-prediction/data/UCF-101/\",\n    \"dataset\": \"UCF-101\",\n    \"end_epoch\": 2,\n    \"ff_dropout\": 0.0,\n    \"frame_len\": 16,\n    \"frame_size\": \"224\",\n    \"gpus\": [\n        0\n    ],\n    \"head\": \"Tempr_h\",\n    \"label_dir\": \"/kaggle/working/progressive-action-prediction/labels/UCF-101\",\n    \"latent_dim\": 512,\n    \"latent_dim_head\": 64,\n    \"latent_heads\": 8,\n    \"log_file\": \"logs/video_pred_at-1c41b535c9e1_datetime_2024-5-18_with_observation_ratio_0.3_Tempr_h_movinet_ada.log\",\n    \"long_cycles\": false,\n    \"lr_base\": 0.01,\n    \"lr_factor\": 0.1,\n    \"lr_mult\": {\n        \"classifier\": 1.0,\n        \"head\": 0.1,\n        \"pool\": 0.1\n    },\n    \"lr_steps\": [\n        14,\n        32,\n        44\n    ],\n    \"max_freq\": 10.0,\n    \"model_dir\": \"./results/observation_ratio_0.3/Tempr_h_movinet_ada\",\n    \"num_freq_bands\": 10,\n    \"num_latents\": 256,\n    \"num_samplers\": 3,\n    \"optimiser\": \"AdamW\",\n    \"pool\": \"ada\",\n    \"precision\": \"mixed\",\n    \"pretrained_dir\": \"/kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth\",\n    \"print_net\": false,\n    \"random_seed\": 1,\n    \"results_dir\": \"./results\",\n    \"resume_epoch\": 0,\n    \"save_frequency\": 1,\n    \"short_cycles\": false,\n    \"train_frame_interval\": [\n        1,\n        2,\n        3,\n        4\n    ],\n    \"use_frames\": false,\n    \"val_frame_interval\": [\n        1,\n        2\n    ],\n    \"video_per\": 0.3,\n    \"video_per_train\": 0.4,\n    \"video_per_val\": 0.4,\n    \"weight_decay\": 1e-05,\n    \"weight_tie_layers\": false,\n    \"workers\": 10\n}\n\u001b[32m2024-05-18 11:41:43\u001b[0m \u001b[35m1c41b535c9e1\u001b[0m \u001b[34mroot[174]\u001b[0m \u001b[1;30mINFO\u001b[0m CUDA availability: True\n\u001b[32m2024-05-18 11:41:43\u001b[0m \u001b[35m1c41b535c9e1\u001b[0m \u001b[34mroot[174]\u001b[0m \u001b[1;30mINFO\u001b[0m Preprocessing:: using default mean & std.\n\nTraceback (most recent call last):\n  File \"/kaggle/working/progressive-action-prediction/train.py\", line 326, in <module>\n    train_data, eval_data, train_length = iterator_factory.create(\n  File \"/kaggle/working/progressive-action-prediction/data/iterator_factory.py\", line 225, in create\n    dataset_iter = get_data(**kwargs)\n  File \"/kaggle/working/progressive-action-prediction/data/iterator_factory.py\", line 131, in get_data\n    train = VideoIter(dataset_location=data_dir,\n  File \"/kaggle/working/progressive-action-prediction/data/video_iterator.py\", line 197, in __init__\n    self.video_dict = self.get_video_dict(location=dataset_location,csv_file=csv_filepath,include_timeslices=include_timeslices)\n  File \"/kaggle/working/progressive-action-prediction/data/video_iterator.py\", line 353, in get_video_dict\n    id = line.get('id').strip()\nAttributeError: 'NoneType' object has no attribute 'strip'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"!python inference.py --config /kaggle/working/progressive-action-prediction/config/inference/smthng-smthng/config.yml --head TemPr_h --pool ada --gpus 0 --pretrained_dir /kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth","metadata":{"execution":{"iopub.status.busy":"2024-05-18T11:44:37.332428Z","iopub.execute_input":"2024-05-18T11:44:37.333155Z","iopub.status.idle":"2024-05-18T11:44:43.571770Z","shell.execute_reply.started":"2024-05-18T11:44:37.333107Z","shell.execute_reply":"2024-05-18T11:44:43.570473Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n  warnings.warn(\nusage: inference.py [-h] [--random_seed RANDOM_SEED] [--print_net PRINT_NET]\n                    [--video_per VIDEO_PER] [--num_samplers NUM_SAMPLERS]\n                    [--dataset {NTU-RGB,UCF-101,HMDB-51,smthng-smthng_coarse,smthng-smthng_fine,smthng-smthng_sub21,smthng-smthng_v2}]\n                    [--data_dir DATA_DIR] [--label_dir LABEL_DIR]\n                    [--json_dir JSON_DIR] [--precision {fp32,mixed}]\n                    [--frame_len FRAME_LEN] [--frame_size FRAME_SIZE]\n                    [--frame_interval FRAME_INTERVAL [FRAME_INTERVAL ...]]\n                    [--gpus GPUS] [--chkp CHKP] [--backbone BACKBONE]\n                    [--head HEAD] [--num_freq_bands NUM_FREQ_BANDS]\n                    [--max_freq MAX_FREQ] [--num_latents NUM_LATENTS]\n                    [--latent_dim LATENT_DIM] [--cross_heads CROSS_HEADS]\n                    [--latent_heads LATENT_HEADS]\n                    [--cross_dim_head CROSS_DIM_HEAD]\n                    [--latent_dim_head LATENT_DIM_HEAD]\n                    [--attn_dropout ATTN_DROPOUT] [--ff_dropout FF_DROPOUT]\n                    [--weight_tie_layers WEIGHT_TIE_LAYERS]\n                    [--use_frames USE_FRAMES]\n                    [--pool {max,avg,em,edscw,idw,ada}] [--workers WORKERS]\n                    [--config CONFIG] [--fp_topk FP_TOPK]\ninference.py: error: unrecognized arguments: --pretrained_dir /kaggle/working/progressive-action-prediction/weights/movinet_ada_best.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"f","metadata":{},"execution_count":null,"outputs":[]}]}